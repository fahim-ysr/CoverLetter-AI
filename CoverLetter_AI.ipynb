{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd28c8d3-7911-4ece-9064-da4706dc0fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required Dependencies:\n",
    "\n",
    "# pip install chromadb\n",
    "# pip install langchain_groq\n",
    "# pip install langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e84289fe-68bd-4036-8161-ab0eecedefac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "# Importing required modules\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "import csv\n",
    "import uuid\n",
    "import chromadb\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25a7d7d0-06f6-4037-a2eb-19ca7bd3b180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracts the Groq API Key from '.env.local' file\n",
    "\n",
    "import os                                                                                                                                                                                                          \n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from pathlib import Path\n",
    "load_dotenv(Path(\".env.local\"))\n",
    "KEY = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25d5464-0e3d-4e8a-8023-70ceda0375db",
   "metadata": {},
   "source": [
    "## Testing the ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "197d1ba3-4db7-4be0-9a4b-7335bdb0a772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's impossible to say definitively who the richest person in history is. \n",
      "\n",
      "Here's why:\n",
      "\n",
      "* **Lack of Consistent Data:**  Reliable wealth records simply don't exist for most of history. We can't accurately compare the wealth of someone who lived in ancient Rome to someone who lived in the 20th century.\n",
      "* **Different Economies:**  The value of money changes drastically over time due to inflation, currency fluctuations, and changes in economic systems. \n",
      "* **Defining \"Wealth\":**  Wealth isn't just about money. It can include land, resources, assets, and even influence and power.  \n",
      "\n",
      "**Some contenders often mentioned in discussions of the richest people in history include:**\n",
      "\n",
      "* **Mansa Musa:** The 14th-century King of Mali, whose wealth from gold and salt mines was legendary.\n",
      "* **Augustus Caesar:** The first Roman Emperor, who controlled vast territories and resources.\n",
      "* **Jacob Fugger:** A 16th-century German merchant and banker who financed the Holy Roman Empire.\n",
      "* **John D. Rockefeller:** The 19th-century American oil tycoon, whose wealth peaked at an estimated $340 billion in today's dollars.\n",
      "\n",
      "**It's important to remember that these are just estimates, and the true answer to the question of who was the richest person in history may never be known.**\n",
      "\n",
      "\n",
      " ***Preambled Answer***\n",
      "\n",
      "Mansa Musa \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Testing if ChatGroq is running correctly\n",
    "\n",
    "llm = ChatGroq(\n",
    "    # model= 'llama-3.3-70b-versatile',\n",
    "    model= 'gemma2-9b-it',\n",
    "    temperature= 0,\n",
    "    groq_api_key= KEY,\n",
    "    max_tokens= None,\n",
    "    timeout= None,\n",
    "    max_retries= 2,\n",
    "    # Other Parameters...\n",
    ")\n",
    "\n",
    "answer = llm.invoke(\"Who is the richest man in the world of all time?\")\n",
    "print(answer.content)\n",
    "print(\"\\n ***Preambled Answer***\\n\")\n",
    "answer = llm.invoke(\"Who is the richest man in the world of all time?, no preamble\")\n",
    "print(answer.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1803bf19-dcd2-4f24-a1b4-0057202fde62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chromadb Setup\n",
    "\n",
    "client = chromadb.Client()\n",
    "collection = client.create_collection(name = \"my_collection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dfa838f8-71e8-4664-9117-f3d39e1abb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.add(\n",
    "    \n",
    "    documents = [\n",
    "        \"I like drinking water everyday\",\n",
    "        \"I like my apple iphone\",\n",
    "        \"Do you like apple?\"\n",
    "    ],\n",
    "\n",
    "    ids = [\"id1\", \"id2\", \"id3\"],\n",
    "\n",
    "    metadatas = [\n",
    "        {\"url\": \"source_to_id1\"},\n",
    "        {\"url\": \"source_to_id2\"},\n",
    "        {\"url\": \"source_to_id3\"},\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "923ed22f-0f2c-4cb0-9e72-0f0776cafd6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ids': ['id1', 'id2', 'id3'], 'embeddings': None, 'documents': ['I like drinking water everyday', 'I like my apple iphone', 'Do you like apple?'], 'uris': None, 'included': ['metadatas', 'documents'], 'data': None, 'metadatas': [{'url': 'source_to_id1'}, {'url': 'source_to_id2'}, {'url': 'source_to_id3'}]}\n"
     ]
    }
   ],
   "source": [
    "print(collection.get())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3988b4d6-c203-47c7-a834-3fe482602780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ids': ['id2'], 'embeddings': None, 'documents': ['I like my apple iphone'], 'uris': None, 'included': ['metadatas', 'documents'], 'data': None, 'metadatas': [{'url': 'source_to_id2'}]}\n"
     ]
    }
   ],
   "source": [
    "print(collection.get(ids = [\"id2\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "419acc0a-c695-4757-9c8c-d6c2ee3ee2df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [['id2', 'id3']],\n",
       " 'embeddings': None,\n",
       " 'documents': [['I like my apple iphone', 'Do you like apple?']],\n",
       " 'uris': None,\n",
       " 'included': ['metadatas', 'documents', 'distances'],\n",
       " 'data': None,\n",
       " 'metadatas': [[{'url': 'source_to_id2'}, {'url': 'source_to_id3'}]],\n",
       " 'distances': [[1.0667046308517456, 1.2515640258789062]]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.query(query_texts = [\"I like technology\"], n_results = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9c07bcf4-3f44-41f9-81ae-cad8bc5101e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [['id1']],\n",
       " 'embeddings': None,\n",
       " 'documents': [['I like drinking water everyday']],\n",
       " 'uris': None,\n",
       " 'included': ['metadatas', 'documents', 'distances'],\n",
       " 'data': None,\n",
       " 'metadatas': [[{'url': 'source_to_id1'}]],\n",
       " 'distances': [[1.3786277770996094]]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.query(query_texts = [\"Do you eat healthy?\"], n_results = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16052f41-4083-40d5-8b77-2fe3fb638cc7",
   "metadata": {},
   "source": [
    "## Extracting Data From Job Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1e007f77-8970-4614-a41a-647c1ac98670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the WebBaseLoader to scrape content of a webpage. Using a demo job description link for testing purposes\n",
    "loader = WebBaseLoader(\"https://amazon.jobs/en/jobs/2729754/cloud-support-intern\")\n",
    "\n",
    "# Stores the loaded data of the webpage\n",
    "data = loader.load().pop().page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "df508916-10c1-4dcb-aef0-a0473849d264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the LLM that is going to be used for data extraction\n",
    "\n",
    "llm = ChatGroq(\n",
    "    model= 'llama-3.3-70b-versatile',\n",
    "    # model= 'gemma2-9b-it',\n",
    "    temperature= 0.5,\n",
    "    groq_api_key= KEY,\n",
    "    max_tokens= None,\n",
    "    timeout= None,\n",
    "    max_retries= 2,\n",
    "    # Other Parameters...\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eb7a6ed8-74a1-4106-9273-83e3f3dd3537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```\n",
      "{\n",
      "  \"role\": \"Cloud Support Intern\",\n",
      "  \"experience\": \"Internship\",\n",
      "  \"skills\": [\n",
      "    \"Cloud computing\",\n",
      "    \"Database, Big Data, Analytics\",\n",
      "    \"Networking (DNS, TCP/IP, HTTP, VLAN, etc.)\",\n",
      "    \"OS (Linux and/or Windows Servers)\",\n",
      "    \"Virtualization (VMware, Xen, Hypervisor)\",\n",
      "    \"Security concepts / best practices\",\n",
      "    \"Storage and Content Delivery\",\n",
      "    \"Deployment\",\n",
      "    \"Developer & Mobile Services (Serverless, Web Mobile, IoT)\",\n",
      "    \"Programming / scripting experience (Java, Perl, Ruby, C#, and/or PHP)\",\n",
      "    \"Korean/English Business Communication Skills\"\n",
      "  ],\n",
      "  \"description\": \"Amazon Web Services (AWS) is seeking a Cloud Support Intern to join their team in Korea. The successful candidate will have a strong focus on customer support, technical troubleshooting, and cloud computing. They will work with leading companies and internal development teams to resolve complex technical issues and drive customer interactions. The intern will also have the opportunity to learn and develop with guidance from their manager, local mentor, and global mentors.\"\n",
      "}\n",
      "```\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# Using prompt on the model\n",
    "\n",
    "extract_from_prompt = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    I will give you scraped text from job postings. Your job is to extract the details and requirements in a JSON format containing the following keywords: 'role', 'experience', 'skills', 'description'\n",
    "    Only return the JSON. No preamble please.\n",
    "    Here is the scraped text: {page_data}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "chain_extract = extract_from_prompt | llm\n",
    "answer = chain_extract.invoke(input= {'page_data': data})\n",
    "print(answer.content)\n",
    "print(type(answer.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0bdd48-0c16-478d-8e63-6b2ff857199a",
   "metadata": {},
   "source": [
    "### Cleaning the JSON (For Gemini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "58282a74-5db5-46cb-a3b7-ef48a6bdf858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"role\": \"Data Engineer/Scientist\",\n",
      "  \"experience\": \"Not specified\",\n",
      "  \"skills\": [\n",
      "    \"Python\",\n",
      "    \"SQL\",\n",
      "    \"Pandas\",\n",
      "    \"Airflow\",\n",
      "    \"PySpark\",\n",
      "    \"Spark SQL\",\n",
      "    \"Delta Lake\",\n",
      "    \"Machine Learning\",\n",
      "    \"Deep Learning\",\n",
      "    \"TensorFlow\",\n",
      "    \"Data Engineering\",\n",
      "    \"ETL\",\n",
      "    \"ELT\",\n",
      "    \"Cloud Platforms (AWS, GCP, Azure)\",\n",
      "    \"Data Warehousing\",\n",
      "    \"Data Modeling\",\n",
      "    \"DBT\",\n",
      "    \"Data Visualization\",\n",
      "    \"Power BI\",\n",
      "    \"Tableau\",\n",
      "    \"MLOps\",\n",
      "    \"MLflow\",\n",
      "    \"Kubeflow\",\n",
      "    \"Natural Language Processing (NLP)\",\n",
      "    \"NLTK\",\n",
      "    \"spaCy\",\n",
      "    \"Computer Vision\",\n",
      "    \"OpenCV\",\n",
      "    \"Time Series Analysis\",\n",
      "    \"Forecasting\",\n",
      "    \"Prophet\",\n",
      "    \"Data Cleaning\",\n",
      "    \"Data Wrangling\",\n",
      "    \"Feature Engineering\",\n",
      "    \"Scikit-learn\",\n",
      "    \"Statistical Analysis\",\n",
      "    \"Hypothesis Testing\",\n",
      "    \"Data Ethics\",\n",
      "    \"Privacy\",\n",
      "    \"GDPR\",\n",
      "    \"Big Data\",\n",
      "    \"Hadoop\",\n",
      "    \"Spark\",\n",
      "    \"Data Governance\",\n",
      "    \"Data Quality\",\n",
      "    \"Metadata Management\",\n",
      "    \"Data Security\",\n",
      "    \"Encryption\",\n",
      "    \"Tokenization\",\n",
      "    \"Cloud Data Engineering\",\n",
      "    \"AWS Glue\",\n",
      "    \"Databricks\"\n",
      "  ],\n",
      "  \"description\": \"The role involves working on various data engineering and science projects, utilizing a range of skills and technologies. Projects include data engineering, machine learning, data visualization, and more.\"\n",
      "}\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "raw_output = answer.content\n",
    "\n",
    "# Remove triple backticks and 'json' if present\n",
    "cleaned_output = raw_output.strip('`json').strip('`')\n",
    "\n",
    "# Load the string as a dictionary\n",
    "data = json.loads(cleaned_output)\n",
    "\n",
    "# Clean up the fields\n",
    "for key in ['role', 'experience', 'skills', 'description']:\n",
    "    if isinstance(data.get(key), str):\n",
    "        data[key] = data[key].replace('\\n', ' ')\n",
    "    elif isinstance(data.get(key), list):\n",
    "        data[key] = [item.replace('\\n', ' ') for item in data[key]]\n",
    "\n",
    "# Now 'data' is your cleaned JSON object\n",
    "cleaned_answer = json.dumps(data, indent=2)\n",
    "print(cleaned_answer)\n",
    "print(type(cleaned_answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bedd2035-46c5-4f4d-a2af-6ae669fd8fc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'Cloud Support Intern',\n",
       " 'experience': 'Internship',\n",
       " 'skills': ['Cloud computing',\n",
       "  'Database, Big Data, Analytics',\n",
       "  'Networking (DNS, TCP/IP, HTTP, VLAN, etc.)',\n",
       "  'OS (Linux and/or Windows Servers)',\n",
       "  'Virtualization (VMware, Xen, Hypervisor)',\n",
       "  'Security concepts / best practices',\n",
       "  'Storage and Content Delivery',\n",
       "  'Deployment',\n",
       "  'Developer & Mobile Services (Serverless, Web Mobile, IoT)',\n",
       "  'Programming / scripting experience (Java, Perl, Ruby, C#, and/or PHP)',\n",
       "  'Korean/English Business Communication Skills'],\n",
       " 'description': 'Amazon Web Services (AWS) is seeking a Cloud Support Intern to join their team in Korea. The successful candidate will have a strong focus on customer support, technical troubleshooting, and cloud computing. They will work with leading companies and internal development teams to resolve complex technical issues and drive customer interactions. The intern will also have the opportunity to learn and develop with guidance from their manager, local mentor, and global mentors.'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting the output into JSON using parser\n",
    "\n",
    "parser = JsonOutputParser()\n",
    "json_answer = parser.parse(answer.content)\n",
    "# json_answer = parser.parse(cleaned_answer)\n",
    "json_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bf7de64c-f4e6-4bde-bb2c-f8c9fba7466a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "# Checking the type of output for confirmation\n",
    "print(type(json_answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144b0b93-6933-4524-a0cb-75dec94365f7",
   "metadata": {},
   "source": [
    "#### Importing Portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3d06eafc-dc03-46f4-83f0-e1feff6c3761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function reads and formats the data in portfolio so that the LLM can understand\n",
    "\n",
    "def read_file(path):\n",
    "    current = []\n",
    "    with open(path, 'r') as file:\n",
    "        csv_reader = csv.reader(file)\n",
    "        next(csv_reader)\n",
    "        for line in csv_reader:\n",
    "            # Formatting data\n",
    "            skills = tuple(line[:-1])\n",
    "            link = line[-1]\n",
    "            current.append((skills, link))\n",
    "        return current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d57e1f94-ce98-4c6a-90ae-38ed051c896f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Python', ' SQL', ' Pandas')  https://github.com/user/project1\n",
      "('SQL', ' Python', ' Airflow')  https://github.com/user/project2\n",
      "('PySpark', ' Spark SQL', ' Delta Lake')  https://github.com/user/project3\n",
      "('Machine Learning', ' Deep Learning', ' TensorFlow')  https://github.com/user/project4\n",
      "('Data Engineering', ' ETL', ' ELT')  https://github.com/user/project5\n",
      "('Cloud Platforms (AWS', ' GCP', ' Azure)')  https://github.com/user/project6\n",
      "('Data Warehousing', ' Data Modeling', ' DBT')  https://github.com/user/project7\n",
      "('Data Visualization', ' Power BI', ' Tableau')  https://github.com/user/project8\n",
      "('MLOps', ' MLflow', ' Kubeflow')  https://github.com/user/project9\n",
      "('Natural Language Processing (NLP)', ' NLTK', ' spaCy')  https://github.com/user/project10\n",
      "('Computer Vision', ' OpenCV', ' TensorFlow')  https://github.com/user/project11\n",
      "('Time Series Analysis', ' Forecasting', ' Prophet')  https://github.com/user/project12\n",
      "('Data Cleaning', ' Data Wrangling', ' Pandas')  https://github.com/user/project13\n",
      "('Feature Engineering', ' Scikit-learn')  https://github.com/user/project14\n",
      "('Statistical Analysis', ' Hypothesis Testing')  https://github.com/user/project15\n",
      "('Data Ethics', ' Privacy', ' GDPR')  https://github.com/user/project16\n",
      "('Big Data', ' Hadoop', ' Spark')  https://github.com/user/project17\n",
      "('Data Governance', ' Data Quality', ' Metadata Management')  https://github.com/user/project18\n",
      "('Data Security', ' Encryption', ' Tokenization')  https://github.com/user/project19\n",
      "('Cloud Data Engineering', ' AWS Glue', ' Databricks')  https://github.com/user/project20\n"
     ]
    }
   ],
   "source": [
    "# Sample Usage\n",
    "\n",
    "path = 'demo_portfolio.csv'\n",
    "data = read_file(path)\n",
    "\n",
    "\n",
    "for skills, link in data:\n",
    "    print(skills, link)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58de9949-eaaf-42ce-9d7d-82c2e852d8dd",
   "metadata": {},
   "source": [
    "#### Inserting data into Vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f64c40dd-0c82-4207-b12d-fc1c23a5f368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chromadb Setup\n",
    "\n",
    "client = chromadb.PersistentClient('vectorstore')\n",
    "collection = client.get_or_create_collection(name= 'portfolio_links')\n",
    "\n",
    "if not collection.count():\n",
    "    for skills, links in data:\n",
    "        collection.add(\n",
    "            documents= str(skills),\n",
    "            metadatas= {'portfolio_url': links},\n",
    "            ids= [str(uuid.uuid4())]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "68eff6be-3b7d-4042-8426-11bd7f4028f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Cloud computing'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displays the first skills required in the sample job description\n",
    "\n",
    "json_answer['skills'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6c6059f2-33a8-48fa-9d8e-794ac614fbbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [['ef2c6826-4e72-4eab-ae48-bf665a2014b0',\n",
       "   'e4f53b41-83e4-4e27-ae4a-8572cff2d108']],\n",
       " 'embeddings': None,\n",
       " 'documents': [[\"('Cloud Platforms (AWS', ' GCP', ' Azure)')\",\n",
       "   \"('Cloud Data Engineering', ' AWS Glue', ' Databricks')\"]],\n",
       " 'uris': None,\n",
       " 'included': ['metadatas', 'documents', 'distances'],\n",
       " 'data': None,\n",
       " 'metadatas': [[{'portfolio_url': ' https://github.com/user/project6'},\n",
       "   {'portfolio_url': ' https://github.com/user/project20'}]],\n",
       " 'distances': [[0.8320648074150085, 0.970432698726654]]}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Queries the portfolio for a relevant project based on the first required skill as above\n",
    "\n",
    "urls = collection.query(query_texts= json_answer['skills'][0], n_results= 2)\n",
    "urls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818e1508-ef79-4967-a6e1-2f2c5fec7e63",
   "metadata": {},
   "source": [
    "## Setting up prompt for writing the email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f8f56c77-e746-46a0-a608-e07de18f9eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning variable for the dob description in JSON\n",
    "\n",
    "job_desc = json_answer['description']\n",
    "\n",
    "# Prompt for the email\n",
    "\n",
    "email_prompt = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    I will give you a role and a task that you have to perform in that specific role.\n",
    "    Your role: Your name is Fahim. You are an incredible business development officer who who knows how to get clients. You work for ABC Consulting Firm, your firm works with all kinds of IT clients and provide solutions in the domain of Data Science and AI.\n",
    "    CoverLetter AI focuses on efficient tailored solutions for all clients keeping costs down. \n",
    "    Your Job: Your Job is to write tailored emails to clients regarding the Job openings that they have advertised. Try to pitch your clients with an email hook that opens a conversation about a possibility of working with them and why they should work with you (advantages and how you are better). Add the most relevant portfolio URLs from\n",
    "    the following (shared below) to showcase that we have the right expertise to get the job done.\n",
    "    Begin with a compelling subject line that references the job title and signals relevance. In the body of the email, include direct reference the job title and requirements to demonstrate your understanding of their needs, and personalize the message by mentioning the company or specific details from the job posting. \n",
    "    Briefly explain how ABC Consulting Firm’s expertise aligns with the role, using the most relevant portfolio URLs provided as specific examples of past success. \n",
    "    Clearly state ABC Consulting Firm’s unique value proposition and what sets your firm apart from others in the industry, demonstrating measurable value your firm can bring to their organization, such as results, efficiencies, or cost savings. \n",
    "    Keep the email professional, convincing and direct maintaining a professional, confident, and approachable tone. Include a clear call to action inviting the HR manager to discuss further or schedule a meeting.\n",
    "    Proofread for correct grammar and spelling, limit the number of links to the most relevant one or two portfolio URLs to avoid spam filters, and avoid excessive formatting or attachments to ensure deliverability. Optionally, you may politely mention that you will follow up if you do not receive a response within a week.\n",
    "    \n",
    "    I will provide you with email and phone number. Email: abc@def.com, Phone: +12345678. Only include them at the end after the initials.\n",
    "    I will now provide you with the Job description and the portfolio URLs:\n",
    "    JOB DESCRIPTION: {job_description}\n",
    "    ------\n",
    "    PORTFOLIO URLS: {portfolio_urls}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# Extracting the answer\n",
    "chain_email = email_prompt | llm\n",
    "answer = chain_email.invoke({'job_description': job_desc, 'portfolio_urls': urls})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b76863f2-d7f7-404d-9fb3-e3f216bd148a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: Application for Cloud Support Intern Role at Amazon Web Services (AWS) in Korea\n",
      "\n",
      "Dear Hiring Manager,\n",
      "\n",
      "I came across the Cloud Support Intern job posting at Amazon Web Services (AWS) in Korea and was impressed by the opportunity to work with a leading company in cloud computing. As a Business Development Officer at ABC Consulting Firm, I believe our expertise in Data Science and AI can bring significant value to your team.\n",
      "\n",
      "The job requirements for a strong focus on customer support, technical troubleshooting, and cloud computing align perfectly with our portfolio. For instance, our experience in Cloud Platforms (AWS, GCP, Azure) and Cloud Data Engineering (AWS Glue, Databricks) can be seen in our successful projects, such as the ones showcased at https://github.com/user/project6. This project demonstrates our ability to design and implement scalable cloud solutions, which can be beneficial in resolving complex technical issues and driving customer interactions.\n",
      "\n",
      "At ABC Consulting Firm, we pride ourselves on providing efficient tailored solutions while keeping costs down. Our unique value proposition lies in our ability to deliver measurable results, efficiencies, and cost savings to our clients. By leveraging our expertise in Data Science and AI, we can help AWS improve customer support, enhance technical troubleshooting, and optimize cloud computing services.\n",
      "\n",
      "I would like to discuss how our firm can support the Cloud Support Intern role and contribute to the success of your team. Our collaborative approach, combined with our technical expertise, can bring significant benefits to your organization.\n",
      "\n",
      "If you are interested in exploring this opportunity further, I would be delighted to schedule a meeting to discuss how ABC Consulting Firm can support your team. Please do not hesitate to contact me at abc@def.com or +12345678.\n",
      "\n",
      "I look forward to the opportunity to discuss this further and explore how we can work together. If I do not hear from you within a week, I will follow up to check on the status of our application.\n",
      "\n",
      "Best regards,\n",
      "Fahim\n"
     ]
    }
   ],
   "source": [
    "# Email that has been generated\n",
    "\n",
    "email = answer.content\n",
    "print(email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b3b210-15c7-447b-b208-9bb9e3c3aad1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
